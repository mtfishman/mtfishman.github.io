<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.png"> <link rel=stylesheet  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"> <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css"> <title>Projects</title> <header> <div class=blog-name ><a href="/">Matthew Fishman</a></div> <nav> <ul> <li><a href="/">Introduction</a> <li><a href="/menu1/">About Me</a> <li><a href="/menu2/">Projects</a> <li><a href="/menu3/">Blog</a> </ul> <img src="/assets/hamburger.svg" id=menu-icon > </nav> </header> <div class=franklin-content > <h1 id=projects ><a href="#projects" class=header-anchor >Projects</a></h1> <div class=franklin-toc ><ol><li><a href="#itensorsjl">ITensors.jl</a><ol><li><a href="#itensorglmakiejl">ITensorGLMakie.jl</a><li><a href="#itensorunicodeplotsjl">ITensorUnicodePlots.jl</a><li><a href="#itensorgaussianmpsjl">ITensorGaussianMPS.jl</a><li><a href="#itensorinfinitempsjl">ITensorInfiniteMPS.jl</a><li><a href="#itensorgpujl">ITensorGPU.jl</a><li><a href="#itensornetworkadjl">ITensorNetworkAD.jl</a><li><a href="#other_extensions_to_itensorsjl">Other extensions to ITensors.jl</a></ol><li><a href="#pastaqjl">PastaQ.jl</a><li><a href="#itensor_c">ITensor &#40;C&#43;&#43;&#41;</a><li><a href="#miscellaneous_julia_packages">Miscellaneous Julia Packages</a><ol><li><a href="#observersjl">Observers.jl</a><li><a href="#serializedelementarraysjl">SerializedElementArrays.jl</a></ol><li><a href="#tensor_network_algorithm_development">Tensor Network algorithm development</a><ol><li><a href="#free_fermion_tensor_networks">Free Fermion Tensor Networks</a><li><a href="#variational_uniform_matrix_product_states_and_tree_tensor_networks">Variational Uniform Matrix Product States and Tree Tensor Networks</a><li><a href="#improved_contraction_methods_for_infinite_2d_tensor_networks">Improved Contraction Methods for Infinite 2D Tensor Networks</a><li><a href="#easing_the_sign_problem_with_variational_circuits_and_automatic_differentation">Easing the Sign Problem with Variational Circuits and Automatic Differentation</a></ol><li><a href="#references">References</a></ol></div> <h1 id=coding_projects ><a href="#coding_projects" class=header-anchor >Coding Projects</a></h1> <h2 id=itensorsjl ><a href="#itensorsjl" class=header-anchor >ITensors.jl</a></h2> <p>I am the lead developer of <a href="https://github.com/ITensor/ITensors.jl">ITensors.jl</a>, a full port of the <a href="https://github.com/ITensor/ITensor">C&#43;&#43; ITensor library</a> to the Julia language. It is a library co-developed with <a href="http://itensor.org/miles"><i class="fas fa-external-link-alt"></i>Miles Stoudenmire</a> for easily developing and running high performance tensor network calculations.</p> <p><i class="fas fa-newspaper"></i> <strong>What&#39;s New:</strong> Derivatives of basic tensor network operations using automatic differentiation are now supported. Reverse mode automatic differentiation &#40;AD&#41; primitives are defined using <a href="https://github.com/JuliaDiff/ChainRules.jl">ChainRules.jl</a>, and derivatives can be computed with AD libraries like <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a>.</p> <p><a href="https://itensor.org"><i class="fas fa-external-link-alt"></i> itensor.org</a></p> <p><a href="https://github.com/ITensor/ITensors.jl"><i class="far fa-github"></i> Source code</a></p> <p><i class="fas fa-file-alt"></i> <span class=bibref ><a href="#fishman2020">Fishman et al. (2020)</a></span></p> <h3 id=itensorglmakiejl ><a href="#itensorglmakiejl" class=header-anchor >ITensorGLMakie.jl</a></h3> <p><a href="https://github.com/ITensor/ITensors.jl/tree/main/ITensorGLMakie">ITensorGLMakie.jl</a> is a package I wrote for easily making interactive visualizations of tensor networks written with ITensors.jl, based on <a href="https://github.com/JuliaPlots/GraphMakie.jl">GraphMakie.jl</a> and <a href="https://github.com/JuliaPlots/Makie.jl">Makie.jl</a>.</p> <p><a href="https://github.com/ITensor/ITensors.jl/tree/main/ITensorGLMakie"><i class="far fa-github"></i> Source code</a></p> <h3 id=itensorunicodeplotsjl ><a href="#itensorunicodeplotsjl" class=header-anchor >ITensorUnicodePlots.jl</a></h3> <p><a href="https://github.com/ITensor/ITensors.jl/tree/main/ITensorUnicodePlots">ITensorUnicodePlots.jl</a> is an alternative backend for visualizing networks of ITensors as text output, based on <a href="https://github.com/JuliaPlots/UnicodePlots.jl">UnicodePlots.jl</a>.</p> <p><a href="https://github.com/ITensor/ITensors.jl/tree/main/ITensorUnicodePlots"><i class="far fa-github"></i> Source code</a></p> <h3 id=itensorgaussianmpsjl ><a href="#itensorgaussianmpsjl" class=header-anchor >ITensorGaussianMPS.jl</a></h3> <p><a href="https://github.com/ITensor/ITensors.jl/tree/main/ITensorGaussianMPS">ITensorGaussianMPS.jl</a> is a Julia package I wrote for transforming free fermion states into tensor network states, based on an algorithm I developed during my Ph.D. with <a href="https://faculty.sites.uci.edu/dmrg/">Steven White</a>.</p> <p><a href="https://github.com/ITensor/ITensors.jl/tree/main/ITensorGaussianMPS"><i class="far fa-github"></i> Source code</a></p> <p><i class="fas fa-file-alt"></i> <span class=bibref ><a href="#fishman2015">Fishman et al. (2015)</a></span></p> <h3 id=itensorinfinitempsjl ><a href="#itensorinfinitempsjl" class=header-anchor >ITensorInfiniteMPS.jl</a></h3> <p><a href="https://github.com/ITensor/ITensorInfiniteMPS.jl">ITensorInfiniteMPS.jl</a> is a Julia package I wrote for extending the functionality of ITensors.jl to infinite MPS.</p> <p><a href="https://github.com/ITensor/ITensorInfiniteMPS.jl"><i class="far fa-github"></i> Source code</a></p> <p><i class="fas fa-file-alt"></i> <span class=bibref ><a href="#stauber2017">Zauner-Stauber et al. (2017)</a></span></p> <h3 id=itensorgpujl ><a href="#itensorgpujl" class=header-anchor >ITensorGPU.jl</a></h3> <p><a href="https://github.com/ITensor/ITensors.jl/tree/main/ITensorGPU">ITensorGPU.jl</a> is a a GPU backend for ITensors.jl primarily written by <a href="https://github.com/kshyatt">Katie Hyatt</a> while she was a postdoc at the CCQ.</p> <p><a href="https://github.com/ITensor/ITensors.jl/tree/main/ITensorGPU"><i class="far fa-github"></i> Source code</a></p> <h3 id=itensornetworkadjl ><a href="#itensornetworkadjl" class=header-anchor >ITensorNetworkAD.jl</a></h3> <p><a href="https://github.com/ITensor/ITensorNetworkAD.jl">ITensorNetworkAD.jl</a> is an experimental tensor network automatic differentiation &#40;AD&#41; library based on <a href="https://github.com/ITensor/ITensors.jl">ITensors.jl</a>, started by <a href="https://linjianma.github.io">Linjian Ma</a> while he was a summer intern at the CCQ. It makes use of <a href="https://github.com/LinjianMa/AutoHOOT">AutoHOOT</a>, a Python library for symbolic derivatives and simplifications of tensor networks.</p> <p><a href="https://github.com/ITensor/ITensorNetworkAD.jl"><i class="far fa-github"></i> Source code</a></p> <h3 id=other_extensions_to_itensorsjl ><a href="#other_extensions_to_itensorsjl" class=header-anchor >Other extensions to ITensors.jl</a></h3> <p>Many packages are in development that extend the functionality of ITensors.jl, such as packages for performing network level contractions and gradient optimizations of tensor networks, packages for interfacing with quantum chemistry libraries like PySCF, and more. Stay tuned and keep an eye out on my <a href="https://github.com/mtfishman"><i class="fas fa-external-link-alt"></i>Github page</a>, the <a href="https://github.com/ITensor"><i class="fas fa-external-link-alt"></i>ITensor Github organization</a>, and the <a href="https://itensor.org"><i class="fas fa-external-link-alt"></i>ITensor website</a>&#33;</p> <h2 id=pastaqjl ><a href="#pastaqjl" class=header-anchor >PastaQ.jl</a></h2> <p><a href="https://github.com/GTorlai/PastaQ.jl">PastaQ.jl</a> is a package I co-develop with <a href="https://github.com/GTorlai">Giacomo Torlai</a> for simulating and analyzing quantum computers, including noisy state and process simulation with customizable noise models, state-of-the-art algorithms for tomography and ongoing work using automatic differentiation to optimize quantum circuits for implementing algorithms like variational quantum eigensolver &#40;VQE&#41; and optimal control.</p> <p><a href="https://pastaq.org"><i class="fas fa-external-link-alt"></i> pastaq.org</a></p> <p><a href="https://github.com/GTorlai/PastaQ.jl"><i class="far fa-github"></i> Source code</a></p> <h2 id=itensor_c ><a href="#itensor_c" class=header-anchor >ITensor &#40;C&#43;&#43;&#41;</a></h2> <p><a href="https://github.com/ITensor/ITensor">ITensor</a> is a C&#43;&#43; library for developing and performing tensor network calculations. I was the lead developer of ITensor V3, the latest major release of the library which had many improvements to the interface and performance of block sparse calculations.</p> <p><a href="https://itensor.org"><i class="fas fa-external-link-alt"></i> itensor.org</a></p> <p><a href="https://github.com/ITensor/ITensor"><i class="far fa-github"></i> Source code</a></p> <h2 id=miscellaneous_julia_packages ><a href="#miscellaneous_julia_packages" class=header-anchor >Miscellaneous Julia Packages</a></h2> <h3 id=observersjl ><a href="#observersjl" class=header-anchor >Observers.jl</a></h3> <p>I co-developed <a href="https://github.com/GTorlai/Observers.jl">Observers.jl</a> with <a href="https://github.com/GTorlai">Giacomo Torlai</a>. It is a package for conveniently specifying a set of measurements you want to make inside of an iterative method.</p> <h3 id=serializedelementarraysjl ><a href="#serializedelementarraysjl" class=header-anchor >SerializedElementArrays.jl</a></h3> <p><a href="https://github.com/ITensor/SerializedElementArrays.jl">SerializedElementArrays.jl</a> is a package I wrote that provides a new Julia Array type &#40;a SerializedElementArray&#41; whose elements are saved to disk. This can help in cases where you have collections of large contiguous data &#40;like an Array of very large Arrays&#41; which individually fit in memory but collectively do not. This is used for the write-to-disk feature in ITensors.jl.</p> <h2 id=tensor_network_algorithm_development ><a href="#tensor_network_algorithm_development" class=header-anchor >Tensor Network algorithm development</a></h2> <h3 id=free_fermion_tensor_networks ><a href="#free_fermion_tensor_networks" class=header-anchor >Free Fermion Tensor Networks</a></h3> <p><a href="https://faculty.sites.uci.edu/dmrg/"><i class="fas fa-external-link-alt"></i>Steven White</a> and I developed an algorithm for obtaining a compact quantum circuit of local gates for a free fermion state. This leads to a straightforward way to construct tensor network state like matrix product states &#40;MPS&#41;, tree tensor networks &#40;TTN&#41;, and multi-scale entanglement renormalization ansatz &#40;MERA&#41; for free fermion states.</p> <p><i class="fas fa-file-alt"></i> <span class=bibref ><a href="#fishman2015">Fishman et al. (2015)</a></span></p> <h3 id=variational_uniform_matrix_product_states_and_tree_tensor_networks ><a href="#variational_uniform_matrix_product_states_and_tree_tensor_networks" class=header-anchor >Variational Uniform Matrix Product States and Tree Tensor Networks</a></h3> <p>In collaboration with colleagues at the University of Ghent and the University of Vienna, I helped to develop a new algorithm for finding ground states of quasi-1D quantum systems directly in the thermodynamic limit, which is faster at finding ground states than the state-of-the-art alternatives. The algorithm is called the variational uniform matrix product state &#40;VUMPS&#41; algorithm.</p> <p><i class="fas fa-file-alt"></i> <span class=bibref ><a href="#stauber2017">Zauner-Stauber et al. (2017)</a></span></p> <p>In collaboration with colleagues at the CCQ, I worked on extending the VUMPS algorithm to solve for ground states of infinite tree tensor networks states, such as states on the Bethe lattices, in an algorithm we called the variational uniform tree state &#40;VUTS&#41; algorithm.</p> <p><i class="fas fa-file-alt"></i> <span class=bibref ><a href="#lunts2020">Lunts et al. (2020)</a></span></p> <h3 id=improved_contraction_methods_for_infinite_2d_tensor_networks ><a href="#improved_contraction_methods_for_infinite_2d_tensor_networks" class=header-anchor >Improved Contraction Methods for Infinite 2D Tensor Networks</a></h3> <p>In collaboration with colleagues at the University of Ghent and the University of Vienna, I worked on extending the VUMPS algorithm to the problem of contracting infinite 2D tensor networks and showed that in many cases it outperforms the standard method, the corner transfer matrix renormalization group &#40;CTMRG&#41; algorithm. In addition, I worked on a fixed point formulation of CTMRG which we also showed was faster than the original CTMRG algorithm, which we called the fixed point corner method &#40;FPCM&#41;.</p> <p><i class="fas fa-file-alt"></i> <span class=bibref ><a href="#fishman2017">Fishman et al. (2017)</a></span></p> <h3 id=easing_the_sign_problem_with_variational_circuits_and_automatic_differentation ><a href="#easing_the_sign_problem_with_variational_circuits_and_automatic_differentation" class=header-anchor >Easing the Sign Problem with Variational Circuits and Automatic Differentation</a></h3> <p>With colleagues from CCQ and other institutions, I helped develop a method for decreasing the average sign of a wavefunction by optimizing a quantum circuit ansatz with automatic differentiation. This could have implications for improving the performance of monte carlo algorithms.</p> <p><i class="fas fa-file-alt"></i> <span class=bibref ><a href="#torlai2019">Torlai et al. (2019)</a></span></p> <h2 id=references ><a href="#references" class=header-anchor >References</a></h2> <p><i class="fas fa-file-alt"></i> <a id=fishman2015  class=anchor ></a><strong>Fishman, White</strong> <a href="https://arxiv.org/abs/1504.07701">Compression of Correlation Matrices and an Efficient Method for Forming Matrix Product States of Fermionic Gaussian States</a>, 2015.</p> <p><i class="fas fa-file-alt"></i> <a id=stauber2017  class=anchor ></a><strong>Zauner-Stauber, Vanderstraeten, Fishman, Verstraete, Haegeman</strong> <a href="https://arxiv.org/abs/1701.07035">Variational optimization algorithms for uniform matrix product states</a>, 2017.</p> <p><i class="fas fa-file-alt"></i> <a id=fishman2017  class=anchor ></a><strong>Fishman, Vanderstraeten, Zauner-Stauber, Haegeman, Verstraete</strong> <a href="https://arxiv.org/abs/1711.05881">Faster Methods for Contracting Infinite 2D Tensor Networks</a>, 2017.</p> <p><i class="fas fa-file-alt"></i> <a id=lunts2020  class=anchor ></a><strong>Lunts, George, Stoudenmire, Fishman</strong> <a href="https://arxiv.org/abs/2010.06543">The Hubbard model on the Bethe lattice via variational uniform tree states: metal-insulator transition and a Fermi liquid</a>, 2020.</p> <p><i class="fas fa-file-alt"></i> <a id=fishman2020  class=anchor ></a><strong>Fishman, White, Stoudenmire</strong> <a href="https://arxiv.org/abs/2007.14822">The ITensor Software Library for Tensor Network Calculations</a>, 2020.</p> <p><i class="fas fa-file-alt"></i> <a id=torlai2019  class=anchor ></a><strong>Torlai, Carrasquilla, Fishman, Melko, Fisher</strong> <a href="https://arxiv.org/abs/1906.04654">Wavefunction positivization via automatic differentiation</a>, 2019.</p> <div class=page-foot > <div class=copyright > &copy; Matthew Fishman. Last modified: December 07, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. View the source code for this website on <a href="https://github.com/mtfishman/mtfishman.github.io">Github</a>. </div> </div> </div>